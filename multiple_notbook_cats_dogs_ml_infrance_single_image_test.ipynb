{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 125,
      "id": "c3156525",
      "metadata": {
        "id": "c3156525"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {
        "id": "5d3ed7a0"
      },
      "outputs": [],
      "source": [
        "DIRECTORY = r'sample_data/'\n",
        "CATEGORIES = ['cats','dogs']"
      ],
      "id": "5d3ed7a0"
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "id": "e56f8318",
      "metadata": {
        "id": "e56f8318"
      },
      "outputs": [],
      "source": [
        "IMG_SIZE = 200\n",
        "\n",
        "data = []\n",
        "\n",
        "for category in CATEGORIES:\n",
        "    folder = os.path.join(DIRECTORY, category)\n",
        "    label = CATEGORIES.index(category)\n",
        "    for img in os.listdir(folder):\n",
        "        img_path = os.path.join(folder, img)\n",
        "        img_arr = cv2.imread(img_path)\n",
        "        img_arr = cv2.resize(img_arr, (IMG_SIZE, IMG_SIZE))\n",
        "        data.append([img_arr, label])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "id": "0ccdcb4a",
      "metadata": {
        "id": "0ccdcb4a",
        "outputId": "7984851f-47cd-4474-f246-5a321569ac25",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3933"
            ]
          },
          "metadata": {},
          "execution_count": 128
        }
      ],
      "source": [
        "len(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "id": "350787a8",
      "metadata": {
        "id": "350787a8"
      },
      "outputs": [],
      "source": [
        "random.shuffle(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "id": "ba6f53d5",
      "metadata": {
        "id": "ba6f53d5"
      },
      "outputs": [],
      "source": [
        "x = []\n",
        "y = []\n",
        "\n",
        "for features, labels in data:\n",
        "    x.append(features)\n",
        "    y.append(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "id": "ec95b34a",
      "metadata": {
        "id": "ec95b34a"
      },
      "outputs": [],
      "source": [
        "x = np.array(x)\n",
        "y = np.array(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "id": "82a76150",
      "metadata": {
        "id": "82a76150"
      },
      "outputs": [],
      "source": [
        "pickle.dump(x, open('x.pkl', 'wb'))\n",
        "pickle.dump(y, open('y.pkl', 'wb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "id": "d78ce195",
      "metadata": {
        "id": "d78ce195"
      },
      "outputs": [],
      "source": [
        "x = pickle.load(open('x.pkl', 'rb'))\n",
        "y = pickle.load(open('y.pkl', 'rb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "id": "8a3ae8e4",
      "metadata": {
        "id": "8a3ae8e4",
        "outputId": "fc3aacb8-ddda-45f6-f5b8-4f862a4c785f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3933, 200, 200, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 134
        }
      ],
      "source": [
        "x.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "id": "4833dccb",
      "metadata": {
        "id": "4833dccb"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "id": "b18f0ed1",
      "metadata": {
        "id": "b18f0ed1"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(64, (3,3), activation = 'relu' ))\n",
        "model.add(MaxPooling2D((2,2)))\n",
        "\n",
        "model.add(Conv2D(64, (3,3), activation = 'relu' ))\n",
        "model.add(MaxPooling2D((2,2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(128, input_shape = x.shape[1:], activation = 'relu'))\n",
        "\n",
        "model.add(Dense(2, activation = 'softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "id": "ee81af83",
      "metadata": {
        "id": "ee81af83"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer = 'adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bde887ef",
      "metadata": {
        "scrolled": true,
        "id": "bde887ef",
        "outputId": "5591ecf4-d9b6-4e19-a041-57e8f90c951c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m475s\u001b[0m 4s/step - accuracy: 0.7680 - loss: 259.7562 - val_accuracy: 0.7817 - val_loss: 0.5340\n",
            "Epoch 2/2\n",
            "\u001b[1m 95/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1:05\u001b[0m 4s/step - accuracy: 0.8140 - loss: 0.4649"
          ]
        }
      ],
      "source": [
        "model.fit(x, y, epochs=2, validation_split=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('sample_data/model.h5')"
      ],
      "metadata": {
        "id": "ll65xpefWzbr"
      },
      "id": "ll65xpefWzbr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import load_model"
      ],
      "metadata": {
        "id": "nQcyyviEwg2r"
      },
      "id": "nQcyyviEwg2r",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define paths\n",
        "MODEL_PATH = \"sample_data/model.h5\"  # Replace with your model's path\n",
        "IMAGE_FOLDER = \"sample_data/test1/\"  # Replace with the folder containing test images\n",
        "TARGET_SIZE = (200, 200)  # Replace with the input size required by your model\n",
        "OUTPUT_FOLDER = \"sample_data/infrance\"  # Folder to save results, optional\n",
        "\n",
        "# Load the model\n",
        "model = load_model(MODEL_PATH)\n",
        "print(\"Model loaded successfully.\")"
      ],
      "metadata": {
        "id": "HVsVETMpwl-D"
      },
      "id": "HVsVETMpwl-D",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure the output folder exists\n",
        "os.makedirs(OUTPUT_FOLDER, exist_ok=True)\n",
        "\n",
        "# Function to preprocess an image\n",
        "def preprocess_image(image_path):\n",
        "    img = cv2.imread(image_path)\n",
        "    if img is None:\n",
        "        print(f\"Failed to load image: {image_path}\")\n",
        "        return None\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert to RGB\n",
        "    img = cv2.resize(img, TARGET_SIZE)  # Resize to the target size\n",
        "    img = img / 255.0  # Normalize pixel values to [0, 1]\n",
        "    img = np.expand_dims(img, axis=0)  # Add batch dimension\n",
        "    return img"
      ],
      "metadata": {
        "id": "0RA4_pOqxGYa"
      },
      "id": "0RA4_pOqxGYa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to perform inference\n",
        "def run_inference(image_folder):\n",
        "    results = []\n",
        "    for file_name in os.listdir(image_folder):\n",
        "        image_path = os.path.join(image_folder, file_name)\n",
        "\n",
        "        if not os.path.isfile(image_path):\n",
        "            print(f\"Skipping non-file: {file_name}\")\n",
        "            continue\n",
        "\n",
        "        # Preprocess the image\n",
        "        preprocessed_img = preprocess_image(image_path)\n",
        "        if preprocessed_img is None:\n",
        "            continue\n",
        "\n",
        "            # Perform inference\n",
        "        prediction = model.predict(preprocessed_img)\n",
        "        print(f\"Prediction for {file_name}: {prediction}\")\n",
        "\n",
        "        # Append results\n",
        "        results.append((file_name, prediction))\n",
        "\n",
        "        # Optional: Save processed images or results\n",
        "        output_image_path = os.path.join(OUTPUT_FOLDER, file_name)\n",
        "        cv2.imwrite(output_image_path, cv2.imread(image_path))  # Save original or annotated image\n",
        "\n",
        "    return results"
      ],
      "metadata": {
        "id": "VtTt0lCVxMoT"
      },
      "id": "VtTt0lCVxMoT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "model = load_model(\"sample_data/model.h5\")\n",
        "print(\"Model input shape:\", model.input_shape)\n"
      ],
      "metadata": {
        "id": "6Wu9_rCZ2Wdm"
      },
      "id": "6Wu9_rCZ2Wdm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run inference on all images in the folder\n",
        "results = run_inference(IMAGE_FOLDER)\n",
        "\n",
        "# Display results\n",
        "for file_name, prediction in results:\n",
        "    print(f\"{file_name}: {prediction}\")"
      ],
      "metadata": {
        "id": "JgTAycAExnMp"
      },
      "id": "JgTAycAExnMp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run inference on all images in the folder\n",
        "results = run_inference(IMAGE_FOLDER)\n",
        "\n",
        "# Display results (file name, prediction, and image)\n",
        "for file_name, prediction in results:\n",
        "    # Assuming a binary classification (cat vs. dog)\n",
        "    label = \"Cat\" if np.argmax(prediction) == 0 else \"Dog\"\n",
        "\n",
        "    # Show the image with the predicted label\n",
        "    img = cv2.imread(os.path.join(IMAGE_FOLDER, file_name))\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB for correct display\n",
        "\n",
        "    plt.imshow(img)\n",
        "    plt.title(f\"{file_name}: {label}\")\n",
        "    plt.axis('off')  # Turn off axis labels\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "HvNzv--l4Xqt"
      },
      "id": "HvNzv--l4Xqt",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}